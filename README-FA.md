&#x202b; در این پروژه ما از دیتاست ( Wisconsin Diagnostic Breast Cancer (WDBCموجود در UCI استفاده خواهیم کرد. این
دیتاست شامل 965 بافت نمونه برداری شده است. بافت هر نمونه، تصویربرداری شده و 11 ویژگی از هستهی سلولهای موجود در هرتصویر مشخص شده است. این ویژگیها عبارتند از:

Radius

Texture

Perimeter

Area

Smoothness

Compactness

Concavity

Number of concave portions of contour

Symmetry

Fractal dimension

هریک از 965 نمونه در این دیتاست، یک بردار ویژگی با طول 01 میباشد. 11 عنصر اول این بردار، میانگین مشخصات لیست شده در بالا برای تصویر گرفته شده از بافت است. 11 عنصر دوم انحراف استاندارد و 11 عنصر آخر بزرگترین مقدار هریک از این ویژگیهای موجود در آن تصویر را مشخص میکند. هر نمونه دارای برچسب 1 یا 1 است که بهترتیب نشاندهنده بدخیم و خوشخیم بودن تومور
آن نمونه است.

&#x202b; این دیتاست به سه مجموعه آموزشی، اعتبارسنجی و تست تقسیم شده و در پوشه Codes&Data قرار گرفته است. نام این فایلها
عبارتند از “TrainX.csv” ، “TrainY.csv” ، “ValidationX.csv” ، “ValidationY.csv” ، “TestX.csv” و “TestY.csv” .
فایلهایی که به “X.csv” ختم میشوند، شامل بردارهای ویژگی هستند و فایلهایی که به “Y.csv” ختم میشوند، شامل برچسب
هر نمونه هستند. هر فایل به شکلی است که هر سطر یک نمونه را نشان میدهد و مقادیر آن نمونه با کاما از هم جدا شده اند.

## &#x202b; یادگیری درخت تصمیم باینری

&#x202b; فایل trainDT.m درخت تصمیم موردنظر را در مرحله آموزش ایجاد میکند. تابع trainDT ، برای انتخاب بهترین ویژگی جهت آزمون در هر مرحله تابع computeOptimalSplit را فراخوانی میکند.


## &#x202b; هرس درخت تصمیم باینری

&#x202b; در
این بخش الگوریتم با استفاده از مجموعه اعتبارسنجی به هرس حریصانه درخت تصمیم میپردازد.
این الگوریتم نسخهای دیگر از روش Reduced Error Pruning  که بدینصورت عمل میکند: یک درخت
تصمیم باینری را به عنوان ورودی میگیرد. یک جستجوی کامل روی همه ی گره های غیربرگ انجام میدهد و از میان آنها گرهای را
برای هرس انتخاب میکند که هرس آن دقت تصمیمگیری بر روی مجموعه اعتبارسنجی را بیشتر از سایر گرهها افزایش دهد. زمانیکه
این گره شناسایی شد آن گره و فرزندانش از درخت حذف شده و با برگی جایگزین میگردد که برچسب نمونه های اکثریت تحت این
شاخه را دارد. بدینصورت یک درخت جدید حاصل میشود. این فرایند تکرار میشود به طوری که هر بار یک گره هرس میشود.
هرس را میتوان آنقدر ادامه داد تا هرس بیشتر سودی نداشته باشد.

&#x202b; برای این منظور تابع pruneSingleGreedyNode.m درخت و مجموعه اعتبارسنجی را
میگیرد و گره ای که کاهش کمتری در دقت مجموعه اعتبارسنجی ایجاد میکند را برای هرس انتخاب میکند و درخت هرس شده را
به عنوان خروجی برمیگرداند. همچنین از دو تابع pruneAllNodes.m و batchClassifyWithDT.m
استفاده شده که تابع اول، لیست تمامی درخته ای حاصل از حذف هر یک از گره ها را بهدست میدهد و تابع دوم با گرفتن یک مجموعه
داده به رده بندی آن توسط درخت تصمیم میپردازد.


